## Identify features of responsible AI (for example, bias, fairness, inclusivity, robustness, safety, veracity).
## Understand how to use tools to identify features of responsible AI (for example, Guardrails for Amazon Bedrock).
## Understand responsible practices to select a model (for example, environmental considerations, sustainability).
## Identify legal risks of working with generative AI (for example, intellectual property infringement claims, biased model outputs, loss of customer trust, end user risk, hallucinations).
## Identify characteristics of datasets (for example, inclusivity, diversity, curated data sources, balanced datasets).
## Understand effects of bias and variance (for example, effects on demographic groups, inaccuracy, overfitting, underfitting).
## Describe tools to detect and monitor bias, trustworthiness, and truthfulness (for example, analyzing label quality, human audits, subgroup analysis, Amazon SageMaker Clarify, SageMaker Model Monitor, Amazon Augmented AI [Amazon A2I]).